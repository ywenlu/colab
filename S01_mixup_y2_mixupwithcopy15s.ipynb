{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 2433.885786,
      "end_time": "2020-08-14T11:07:00.653314",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-08-14T10:26:26.767528",
      "version": "2.1.0"
    },
    "colab": {
      "name": "S01_mixup_y2_mixupwithcopy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ywenlu/colab/blob/master/S01_mixup_y2_mixupwithcopy15s.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K7MJeuGbiN_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "70d3f833-d3f4-4412-9cf9-a18a02b90993"
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Sep  7 20:25:55 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P0    51W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju8eK_T9SJCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gcsfs==0.6.2 soundfile==0.10.3.post1 catalyst==20.8.2 >> /dev/null"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:31.262304Z",
          "iopub.status.busy": "2020-08-14T10:26:31.261641Z",
          "iopub.status.idle": "2020-08-14T10:26:43.679533Z",
          "shell.execute_reply": "2020-08-14T10:26:43.678430Z"
        },
        "papermill": {
          "duration": 12.43994,
          "end_time": "2020-08-14T10:26:43.679682",
          "exception": false,
          "start_time": "2020-08-14T10:26:31.239742",
          "status": "completed"
        },
        "tags": [],
        "id": "u5W4iVBQN32z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6543768b-b26a-4d87-f817-a2cb6a7c6431"
      },
      "source": [
        "import cv2\n",
        "import audioread\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import librosa\n",
        "import librosa.display as display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torch import save\n",
        "\n",
        "from contextlib import contextmanager\n",
        "from IPython.display import Audio\n",
        "from pathlib import Path\n",
        "from typing import Optional, List\n",
        "\n",
        "from catalyst.dl import SupervisedRunner, State, CallbackOrder, Callback, CheckpointCallback, IRunner\n",
        "from catalyst.core import utils\n",
        "from fastprogress import progress_bar\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, average_precision_score\n",
        "import gcsfs\n",
        "import pathlib\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D-INeUFb4tM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "version_name = 'S01_mixupwithcopy_15s'\n",
        "weight_path = '/content/gdrive/My Drive/kaggle/Birdcall/weight/'+version_name\n",
        "import os\n",
        "## Check path for checkpoint \n",
        "if not os.path.exists(weight_path):\n",
        "    os.makedirs(weight_path)\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:43.721167Z",
          "iopub.status.busy": "2020-08-14T10:26:43.720157Z",
          "iopub.status.idle": "2020-08-14T10:26:43.726429Z",
          "shell.execute_reply": "2020-08-14T10:26:43.725812Z"
        },
        "papermill": {
          "duration": 0.033698,
          "end_time": "2020-08-14T10:26:43.726552",
          "exception": false,
          "start_time": "2020-08-14T10:26:43.692854",
          "status": "completed"
        },
        "tags": [],
        "id": "89q01yKaN322",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "    \n",
        "    \n",
        "def get_logger(out_file=None):\n",
        "    logger = logging.getLogger()\n",
        "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "    logger.handlers = []\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    handler = logging.StreamHandler()\n",
        "    handler.setFormatter(formatter)\n",
        "    handler.setLevel(logging.INFO)\n",
        "    logger.addHandler(handler)\n",
        "\n",
        "    if out_file is not None:\n",
        "        fh = logging.FileHandler(out_file)\n",
        "        fh.setFormatter(formatter)\n",
        "        fh.setLevel(logging.INFO)\n",
        "        logger.addHandler(fh)\n",
        "    logger.info(\"logger set up\")\n",
        "    return logger\n",
        "    \n",
        "    \n",
        "@contextmanager\n",
        "def timer(name: str, logger: Optional[logging.Logger] = None):\n",
        "    t0 = time.time()\n",
        "    msg = f\"[{name}] start\"\n",
        "    if logger is None:\n",
        "        print(msg)\n",
        "    else:\n",
        "        logger.info(msg)\n",
        "    yield\n",
        "\n",
        "    msg = f\"[{name}] done in {time.time() - t0:.2f} s\"\n",
        "    if logger is None:\n",
        "        print(msg)\n",
        "    else:\n",
        "        logger.info(msg)\n",
        "    \n",
        "    \n",
        "set_seed(28)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_kg_hide-input": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:43.757897Z",
          "iopub.status.busy": "2020-08-14T10:26:43.757128Z",
          "iopub.status.idle": "2020-08-14T10:26:43.759607Z",
          "shell.execute_reply": "2020-08-14T10:26:43.760169Z"
        },
        "papermill": {
          "duration": 0.021548,
          "end_time": "2020-08-14T10:26:43.760287",
          "exception": false,
          "start_time": "2020-08-14T10:26:43.738739",
          "status": "completed"
        },
        "tags": [],
        "id": "GuFViI-mN326",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fs = gcsfs.GCSFileSystem(project='bird')\n",
        "\n",
        "birdsong_recognition_path = \"gs://kds-bc7c7091d71391e41129a01940482e83a80019f27cf5b649d4be2877/\"\n",
        "birdcall_check_path = \"gs://kds-47293e6f23bfd75c004f9a52b2e01b23048b68a2c202fff4e89e8234/\"\n",
        "pannscnn14_decisionlevelatt_weight_path = \"gs://kds-3ea036f7f5d93d3322e8f3004334fe4045540d70c5b25bfa57d26bef/\"\n",
        "birdsong_resampled_train_audio_00_path = \"gs://kds-24267f1fe6397b8ac019ca501468321dd1a450924510fbeec1ace944/\"\n",
        "birdsong_resampled_train_audio_01_path = \"gs://kds-3daf4d6df300baaa8960c9982fc6fce96928e85c317ab5c75dae6353/\"\n",
        "birdsong_resampled_train_audio_02_path = \"gs://kds-6cf7d7e59baec8c24e09ba858d02b5036d33f470cf51b52754ce291f/\"\n",
        "birdsong_resampled_train_audio_03_path = \"gs://kds-09d190e6b962a98730eb344cf2eafa24f15a73e9b035f86d13be0ef5/\"\n",
        "birdsong_resampled_train_audio_04_path = \"gs://kds-2c014fc9e001b0f35c7a821957d8f34fac19cd86169820062ccce29d/\"\n",
        "RAW_DATA = birdsong_recognition_path\n",
        "TRAIN_AUDIO_DIR = RAW_DATA + \"train_audio\"\n",
        "TRAIN_RESAMPLED_AUDIO_DIRS = [\n",
        "  birdsong_resampled_train_audio_00_path,\n",
        "  birdsong_resampled_train_audio_01_path,\n",
        "  birdsong_resampled_train_audio_02_path,\n",
        "  birdsong_resampled_train_audio_03_path,\n",
        "  birdsong_resampled_train_audio_04_path\n",
        "]\n",
        "TEST_AUDIO_DIR = RAW_DATA + \"test_audio\"\n",
        "BIRDCALL_CHECK = birdcall_check_path\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7JhDFowenIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "f07a5925-3cf2-4e10-8803-b610489cf901"
      },
      "source": [
        "!gsutil cp '{pannscnn14_decisionlevelatt_weight_path}Cnn14_DecisionLevelAtt_mAP0.425.pth' ."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://kds-3ea036f7f5d93d3322e8f3004334fe4045540d70c5b25bfa57d26bef/Cnn14_DecisionLevelAtt_mAP0.425.pth...\n",
            "- [1 files][316.4 MiB/316.4 MiB]                                                \n",
            "Operation completed over 1 objects/316.4 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:43.794375Z",
          "iopub.status.busy": "2020-08-14T10:26:43.793466Z",
          "iopub.status.idle": "2020-08-14T10:26:44.076854Z",
          "shell.execute_reply": "2020-08-14T10:26:44.075869Z"
        },
        "papermill": {
          "duration": 0.30389,
          "end_time": "2020-08-14T10:26:44.076977",
          "exception": false,
          "start_time": "2020-08-14T10:26:43.773087",
          "status": "completed"
        },
        "tags": [],
        "id": "5Yf9sPLxN329",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(TRAIN_RESAMPLED_AUDIO_DIRS[0] + \"train_mod.csv\")\n",
        "\n",
        "if not fs.exists(TEST_AUDIO_DIR):\n",
        "    TEST_AUDIO_DIR = BIRDCALL_CHECK + \"test_audio\"\n",
        "    test = pd.read_csv(BIRDCALL_CHECK + \"test.csv\")\n",
        "else:\n",
        "    test = pd.read_csv(RAW_DATA + \"test.csv\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:44.186427Z",
          "iopub.status.busy": "2020-08-14T10:26:44.160452Z",
          "iopub.status.idle": "2020-08-14T10:26:44.202387Z",
          "shell.execute_reply": "2020-08-14T10:26:44.201812Z"
        },
        "papermill": {
          "duration": 0.062799,
          "end_time": "2020-08-14T10:26:44.202497",
          "exception": false,
          "start_time": "2020-08-14T10:26:44.139698",
          "status": "completed"
        },
        "tags": [],
        "id": "umRrqlQyN33A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DFTBase(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"Base class for DFT and IDFT matrix\"\"\"\n",
        "        super(DFTBase, self).__init__()\n",
        "\n",
        "    def dft_matrix(self, n):\n",
        "        (x, y) = np.meshgrid(np.arange(n), np.arange(n))\n",
        "        omega = np.exp(-2 * np.pi * 1j / n)\n",
        "        W = np.power(omega, x * y)\n",
        "        return W\n",
        "\n",
        "    def idft_matrix(self, n):\n",
        "        (x, y) = np.meshgrid(np.arange(n), np.arange(n))\n",
        "        omega = np.exp(2 * np.pi * 1j / n)\n",
        "        W = np.power(omega, x * y)\n",
        "        return W\n",
        "    \n",
        "    \n",
        "class STFT(DFTBase):\n",
        "    def __init__(self, n_fft=2048, hop_length=None, win_length=None, \n",
        "        window='hann', center=True, pad_mode='reflect', freeze_parameters=True):\n",
        "        \"\"\"Implementation of STFT with Conv1d. The function has the same output \n",
        "        of librosa.core.stft\n",
        "        \"\"\"\n",
        "        super(STFT, self).__init__()\n",
        "\n",
        "        assert pad_mode in ['constant', 'reflect']\n",
        "\n",
        "        self.n_fft = n_fft\n",
        "        self.center = center\n",
        "        self.pad_mode = pad_mode\n",
        "\n",
        "        # By default, use the entire frame\n",
        "        if win_length is None:\n",
        "            win_length = n_fft\n",
        "\n",
        "        # Set the default hop, if it's not already specified\n",
        "        if hop_length is None:\n",
        "            hop_length = int(win_length // 4)\n",
        "\n",
        "        fft_window = librosa.filters.get_window(window, win_length, fftbins=True)\n",
        "\n",
        "        # Pad the window out to n_fft size\n",
        "        fft_window = librosa.util.pad_center(fft_window, n_fft)\n",
        "\n",
        "        # DFT & IDFT matrix\n",
        "        self.W = self.dft_matrix(n_fft)\n",
        "\n",
        "        out_channels = n_fft // 2 + 1\n",
        "\n",
        "        self.conv_real = nn.Conv1d(in_channels=1, out_channels=out_channels, \n",
        "            kernel_size=n_fft, stride=hop_length, padding=0, dilation=1, \n",
        "            groups=1, bias=False)\n",
        "\n",
        "        self.conv_imag = nn.Conv1d(in_channels=1, out_channels=out_channels, \n",
        "            kernel_size=n_fft, stride=hop_length, padding=0, dilation=1, \n",
        "            groups=1, bias=False)\n",
        "\n",
        "        self.conv_real.weight.data = torch.Tensor(\n",
        "            np.real(self.W[:, 0 : out_channels] * fft_window[:, None]).T)[:, None, :]\n",
        "        # (n_fft // 2 + 1, 1, n_fft)\n",
        "\n",
        "        self.conv_imag.weight.data = torch.Tensor(\n",
        "            np.imag(self.W[:, 0 : out_channels] * fft_window[:, None]).T)[:, None, :]\n",
        "        # (n_fft // 2 + 1, 1, n_fft)\n",
        "\n",
        "        if freeze_parameters:\n",
        "            for param in self.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"input: (batch_size, data_length)\n",
        "        Returns:\n",
        "          real: (batch_size, n_fft // 2 + 1, time_steps)\n",
        "          imag: (batch_size, n_fft // 2 + 1, time_steps)\n",
        "        \"\"\"\n",
        "\n",
        "        x = input[:, None, :]   # (batch_size, channels_num, data_length)\n",
        "\n",
        "        if self.center:\n",
        "            x = F.pad(x, pad=(self.n_fft // 2, self.n_fft // 2), mode=self.pad_mode)\n",
        "\n",
        "        real = self.conv_real(x)\n",
        "        imag = self.conv_imag(x)\n",
        "        # (batch_size, n_fft // 2 + 1, time_steps)\n",
        "\n",
        "        real = real[:, None, :, :].transpose(2, 3)\n",
        "        imag = imag[:, None, :, :].transpose(2, 3)\n",
        "        # (batch_size, 1, time_steps, n_fft // 2 + 1)\n",
        "\n",
        "        return real, imag\n",
        "    \n",
        "    \n",
        "class Spectrogram(nn.Module):\n",
        "    def __init__(self, n_fft=2048, hop_length=None, win_length=None, \n",
        "        window='hann', center=True, pad_mode='reflect', power=2.0, \n",
        "        freeze_parameters=True):\n",
        "        \"\"\"Calculate spectrogram using pytorch. The STFT is implemented with \n",
        "        Conv1d. The function has the same output of librosa.core.stft\n",
        "        \"\"\"\n",
        "        super(Spectrogram, self).__init__()\n",
        "\n",
        "        self.power = power\n",
        "\n",
        "        self.stft = STFT(n_fft=n_fft, hop_length=hop_length, \n",
        "            win_length=win_length, window=window, center=center, \n",
        "            pad_mode=pad_mode, freeze_parameters=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"input: (batch_size, 1, time_steps, n_fft // 2 + 1)\n",
        "        Returns:\n",
        "          spectrogram: (batch_size, 1, time_steps, n_fft // 2 + 1)\n",
        "        \"\"\"\n",
        "\n",
        "        (real, imag) = self.stft.forward(input)\n",
        "        # (batch_size, n_fft // 2 + 1, time_steps)\n",
        "\n",
        "        spectrogram = real ** 2 + imag ** 2\n",
        "\n",
        "        if self.power == 2.0:\n",
        "            pass\n",
        "        else:\n",
        "            spectrogram = spectrogram ** (power / 2.0)\n",
        "\n",
        "        return spectrogram\n",
        "\n",
        "    \n",
        "class LogmelFilterBank(nn.Module):\n",
        "    def __init__(self, sr=32000, n_fft=2048, n_mels=64, fmin=50, fmax=14000, is_log=True, \n",
        "        ref=1.0, amin=1e-10, top_db=80.0, freeze_parameters=True):\n",
        "        \"\"\"Calculate logmel spectrogram using pytorch. The mel filter bank is \n",
        "        the pytorch implementation of as librosa.filters.mel \n",
        "        \"\"\"\n",
        "        super(LogmelFilterBank, self).__init__()\n",
        "\n",
        "        self.is_log = is_log\n",
        "        self.ref = ref\n",
        "        self.amin = amin\n",
        "        self.top_db = top_db\n",
        "\n",
        "        self.melW = librosa.filters.mel(sr=sr, n_fft=n_fft, n_mels=n_mels,\n",
        "            fmin=fmin, fmax=fmax).T\n",
        "        # (n_fft // 2 + 1, mel_bins)\n",
        "\n",
        "        self.melW = nn.Parameter(torch.Tensor(self.melW))\n",
        "\n",
        "        if freeze_parameters:\n",
        "            for param in self.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"input: (batch_size, channels, time_steps)\n",
        "        \n",
        "        Output: (batch_size, time_steps, mel_bins)\n",
        "        \"\"\"\n",
        "\n",
        "        # Mel spectrogram\n",
        "        mel_spectrogram = torch.matmul(input, self.melW)\n",
        "\n",
        "        # Logmel spectrogram\n",
        "        if self.is_log:\n",
        "            output = self.power_to_db(mel_spectrogram)\n",
        "        else:\n",
        "            output = mel_spectrogram\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def power_to_db(self, input):\n",
        "        \"\"\"Power to db, this function is the pytorch implementation of \n",
        "        librosa.core.power_to_lb\n",
        "        \"\"\"\n",
        "        ref_value = self.ref\n",
        "        log_spec = 10.0 * torch.log10(torch.clamp(input, min=self.amin, max=np.inf))\n",
        "        log_spec -= 10.0 * np.log10(np.maximum(self.amin, ref_value))\n",
        "\n",
        "        if self.top_db is not None:\n",
        "            if self.top_db < 0:\n",
        "                raise ParameterError('top_db must be non-negative')\n",
        "            log_spec = torch.clamp(log_spec, min=log_spec.max().item() - self.top_db, max=np.inf)\n",
        "\n",
        "        return log_spec"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:44.246248Z",
          "iopub.status.busy": "2020-08-14T10:26:44.240679Z",
          "iopub.status.idle": "2020-08-14T10:26:44.249107Z",
          "shell.execute_reply": "2020-08-14T10:26:44.248561Z"
        },
        "papermill": {
          "duration": 0.03404,
          "end_time": "2020-08-14T10:26:44.249211",
          "exception": false,
          "start_time": "2020-08-14T10:26:44.215171",
          "status": "completed"
        },
        "tags": [],
        "id": "cXsAjGLMN33C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DropStripes(nn.Module):\n",
        "    def __init__(self, dim, drop_width, stripes_num):\n",
        "        \"\"\"Drop stripes. \n",
        "        Args:\n",
        "          dim: int, dimension along which to drop\n",
        "          drop_width: int, maximum width of stripes to drop\n",
        "          stripes_num: int, how many stripes to drop\n",
        "        \"\"\"\n",
        "        super(DropStripes, self).__init__()\n",
        "\n",
        "        assert dim in [2, 3]    # dim 2: time; dim 3: frequency\n",
        "\n",
        "        self.dim = dim\n",
        "        self.drop_width = drop_width\n",
        "        self.stripes_num = stripes_num\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"input: (batch_size, channels, time_steps, freq_bins)\"\"\"\n",
        "\n",
        "        assert input.ndimension() == 4\n",
        "\n",
        "        if self.training is False:\n",
        "            return input\n",
        "\n",
        "        else:\n",
        "            batch_size = input.shape[0]\n",
        "            total_width = input.shape[self.dim]\n",
        "\n",
        "            for n in range(batch_size):\n",
        "                self.transform_slice(input[n], total_width)\n",
        "\n",
        "            return input\n",
        "\n",
        "\n",
        "    def transform_slice(self, e, total_width):\n",
        "        \"\"\"e: (channels, time_steps, freq_bins)\"\"\"\n",
        "\n",
        "        for _ in range(self.stripes_num):\n",
        "            distance = torch.randint(low=0, high=self.drop_width, size=(1,))[0]\n",
        "            bgn = torch.randint(low=0, high=total_width - distance, size=(1,))[0]\n",
        "\n",
        "            if self.dim == 2:\n",
        "                e[:, bgn : bgn + distance, :] = 0\n",
        "            elif self.dim == 3:\n",
        "                e[:, :, bgn : bgn + distance] = 0\n",
        "\n",
        "\n",
        "class SpecAugmentation(nn.Module):\n",
        "    def __init__(self, time_drop_width, time_stripes_num, freq_drop_width, \n",
        "        freq_stripes_num):\n",
        "        \"\"\"Spec augmetation. \n",
        "        [ref] Park, D.S., Chan, W., Zhang, Y., Chiu, C.C., Zoph, B., Cubuk, E.D. \n",
        "        and Le, Q.V., 2019. Specaugment: A simple data augmentation method \n",
        "        for automatic speech recognition. arXiv preprint arXiv:1904.08779.\n",
        "        Args:\n",
        "          time_drop_width: int\n",
        "          time_stripes_num: int\n",
        "          freq_drop_width: int\n",
        "          freq_stripes_num: int\n",
        "        \"\"\"\n",
        "\n",
        "        super(SpecAugmentation, self).__init__()\n",
        "\n",
        "        self.time_dropper = DropStripes(dim=2, drop_width=time_drop_width, \n",
        "            stripes_num=time_stripes_num)\n",
        "\n",
        "        self.freq_dropper = DropStripes(dim=3, drop_width=freq_drop_width, \n",
        "            stripes_num=freq_stripes_num)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.time_dropper(input)\n",
        "        x = self.freq_dropper(x)\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:44.384942Z",
          "iopub.status.busy": "2020-08-14T10:26:44.363459Z",
          "iopub.status.idle": "2020-08-14T10:26:44.388830Z",
          "shell.execute_reply": "2020-08-14T10:26:44.388352Z"
        },
        "papermill": {
          "duration": 0.051099,
          "end_time": "2020-08-14T10:26:44.388925",
          "exception": false,
          "start_time": "2020-08-14T10:26:44.337826",
          "status": "completed"
        },
        "tags": [],
        "id": "8ckM77NFN33I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_layer(layer):\n",
        "    nn.init.xavier_uniform_(layer.weight)\n",
        "\n",
        "    if hasattr(layer, \"bias\"):\n",
        "        if layer.bias is not None:\n",
        "            layer.bias.data.fill_(0.)\n",
        "\n",
        "\n",
        "def init_bn(bn):\n",
        "    bn.bias.data.fill_(0.)\n",
        "    bn.weight.data.fill_(1.0)\n",
        "\n",
        "\n",
        "def interpolate(x: torch.Tensor, ratio: int):\n",
        "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
        "    resolution reduction in downsampling of a CNN.\n",
        "\n",
        "    Args:\n",
        "      x: (batch_size, time_steps, classes_num)\n",
        "      ratio: int, ratio to interpolate\n",
        "    Returns:\n",
        "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
        "    \"\"\"\n",
        "    (batch_size, time_steps, classes_num) = x.shape\n",
        "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
        "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
        "    return upsampled\n",
        "\n",
        "\n",
        "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
        "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
        "    is the same as the value of the last frame.\n",
        "    Args:\n",
        "      framewise_output: (batch_size, frames_num, classes_num)\n",
        "      frames_num: int, number of frames to pad\n",
        "    Outputs:\n",
        "      output: (batch_size, frames_num, classes_num)\n",
        "    \"\"\"\n",
        "    pad = framewise_output[:, -1:, :].repeat(\n",
        "        1, frames_num - framewise_output.shape[1], 1)\n",
        "    \"\"\"tensor for padding\"\"\"\n",
        "\n",
        "    output = torch.cat((framewise_output, pad), dim=1)\n",
        "    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1),\n",
        "            bias=False)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=out_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1),\n",
        "            bias=False)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        init_layer(self.conv1)\n",
        "        init_layer(self.conv2)\n",
        "        init_bn(self.bn1)\n",
        "        init_bn(self.bn2)\n",
        "\n",
        "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
        "\n",
        "        x = input\n",
        "        x = F.relu_(self.bn1(self.conv1(x)))\n",
        "        x = F.relu_(self.bn2(self.conv2(x)))\n",
        "        if pool_type == 'max':\n",
        "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
        "        elif pool_type == 'avg':\n",
        "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
        "        elif pool_type == 'avg+max':\n",
        "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
        "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
        "            x = x1 + x2\n",
        "        else:\n",
        "            raise Exception('Incorrect argument!')\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class AttBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_features: int,\n",
        "                 out_features: int,\n",
        "                 activation=\"linear\",\n",
        "                 temperature=1.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.activation = activation\n",
        "        self.temperature = temperature\n",
        "        self.att = nn.Conv1d(\n",
        "            in_channels=in_features,\n",
        "            out_channels=out_features,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            bias=True)\n",
        "        self.cla = nn.Conv1d(\n",
        "            in_channels=in_features,\n",
        "            out_channels=out_features,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            bias=True)\n",
        "\n",
        "        self.bn_att = nn.BatchNorm1d(out_features)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        init_layer(self.att)\n",
        "        init_layer(self.cla)\n",
        "        init_bn(self.bn_att)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (n_samples, n_in, n_time)\n",
        "        norm_att = torch.softmax(torch.clamp(self.att(x), -10, 10), dim=-1)\n",
        "        cla = self.nonlinear_transform(self.cla(x))\n",
        "        x = torch.sum(norm_att * cla, dim=2)\n",
        "        return x, norm_att, cla\n",
        "\n",
        "    def nonlinear_transform(self, x):\n",
        "        if self.activation == 'linear':\n",
        "            return x\n",
        "        elif self.activation == 'sigmoid':\n",
        "            return torch.sigmoid(x)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-MZWdxMpo9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mixup(object):\n",
        "    def __init__(self, mixup_alpha, random_seed=1234):\n",
        "        \"\"\"Mixup coefficient generator.\n",
        "        \"\"\"\n",
        "        self.mixup_alpha = mixup_alpha\n",
        "        self.random_state = np.random.RandomState(random_seed)\n",
        "\n",
        "    def get_lambda(self, batch_size):\n",
        "\n",
        "        mixup_lambdas = []\n",
        "        for n in range(0, batch_size):\n",
        "            lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
        "            mixup_lambdas.append(lam)\n",
        "        rand_idx = np.arange(batch_size)\n",
        "        np.random.shuffle(rand_idx)\n",
        "        return np.array(mixup_lambdas), rand_idx\n",
        "\n",
        "def do_mixup(x, mixup_lambda,shuffle_idx):\n",
        "    # if torch.is_tensor(x):\n",
        "    mixup_lambda = torch.from_numpy(mixup_lambda).to(device, non_blocking=True)\n",
        "\n",
        "    out = x*mixup_lambda + x[shuffle_idx]*(1-mixup_lambda)\n",
        "    # out = (x[0 :: 2].transpose(0, -1) * mixup_lambda+ \\\n",
        "    #     x[1 :: 2].transpose(0, -1) * mixup_lambda[1 :: 2]).transpose(0, -1)\n",
        "    # # if torch.is_tensor(out):\n",
        "    #     out = out.float()\n",
        "    return out.float()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:44.451102Z",
          "iopub.status.busy": "2020-08-14T10:26:44.432124Z",
          "iopub.status.idle": "2020-08-14T10:26:44.453850Z",
          "shell.execute_reply": "2020-08-14T10:26:44.453343Z"
        },
        "papermill": {
          "duration": 0.052706,
          "end_time": "2020-08-14T10:26:44.453941",
          "exception": false,
          "start_time": "2020-08-14T10:26:44.401235",
          "status": "completed"
        },
        "tags": [],
        "id": "reO0fML8N33S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PANNsCNN14Att(nn.Module):\n",
        "    def __init__(self, sample_rate: int, window_size: int, hop_size: int,\n",
        "                 mel_bins: int, fmin: int, fmax: int, classes_num: int):\n",
        "        super().__init__()\n",
        "\n",
        "        window = 'hann'\n",
        "        center = True\n",
        "        pad_mode = 'reflect'\n",
        "        ref = 1.0\n",
        "        amin = 1e-10\n",
        "        top_db = None\n",
        "        self.interpolate_ratio = 32  # Downsampled ratio\n",
        "\n",
        "        self.mixup_coff = Mixup(1.)\n",
        "\n",
        "\n",
        "        # Spectrogram extractor\n",
        "        self.spectrogram_extractor = Spectrogram(\n",
        "            n_fft=window_size,\n",
        "            hop_length=hop_size,\n",
        "            win_length=window_size,\n",
        "            window=window,\n",
        "            center=center,\n",
        "            pad_mode=pad_mode,\n",
        "            freeze_parameters=True)\n",
        "\n",
        "        # Logmel feature extractor\n",
        "        self.logmel_extractor = LogmelFilterBank(\n",
        "            sr=sample_rate,\n",
        "            n_fft=window_size,\n",
        "            n_mels=mel_bins,\n",
        "            fmin=fmin,\n",
        "            fmax=fmax,\n",
        "            ref=ref,\n",
        "            amin=amin,\n",
        "            top_db=top_db,\n",
        "            freeze_parameters=True)\n",
        "\n",
        "        # Spec augmenter\n",
        "        self.spec_augmenter = SpecAugmentation(\n",
        "            time_drop_width=64,\n",
        "            time_stripes_num=2,\n",
        "            freq_drop_width=8,\n",
        "            freq_stripes_num=2)\n",
        "\n",
        "        self.bn0 = nn.BatchNorm2d(mel_bins)\n",
        "\n",
        "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n",
        "        self.conv_block2 = ConvBlock(in_channels=64, out_channels=128)\n",
        "        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n",
        "        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n",
        "        self.conv_block5 = ConvBlock(in_channels=512, out_channels=1024)\n",
        "        self.conv_block6 = ConvBlock(in_channels=1024, out_channels=2048)\n",
        "\n",
        "        self.fc1 = nn.Linear(2048, 2048, bias=True)\n",
        "        self.att_block = AttBlock(2048, classes_num, activation='sigmoid')\n",
        "\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        init_bn(self.bn0)\n",
        "        init_layer(self.fc1)\n",
        "        \n",
        "    def cnn_feature_extractor(self, x):\n",
        "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block5(x, pool_size=(2, 2), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv_block6(x, pool_size=(1, 1), pool_type='avg')\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        return x\n",
        "    \n",
        "    def preprocess(self, input, mixup_lambda=None):\n",
        "        # t1 = time.time()\n",
        "        x = self.spectrogram_extractor(input)  # (batch_size, 1, time_steps, freq_bins)\n",
        "        x = self.logmel_extractor(x)  # (batch_size, 1, time_steps, mel_bins)\n",
        "\n",
        "        frames_num = x.shape[2]\n",
        "\n",
        "        x = x.transpose(1, 3)\n",
        "        x = self.bn0(x)\n",
        "        x = x.transpose(1, 3)\n",
        "\n",
        "        if self.training:\n",
        "            x = self.spec_augmenter(x)\n",
        "        \n",
        "\n",
        "        # Mixup on spectrogram\n",
        "        if self.training and random.random()<0.55 and mixup_lambda is not None:\n",
        "            mixup_lambda, shuffle_idx = self.mixup_coff.get_lambda(x.shape[0])\n",
        "            x = do_mixup(x, mixup_lambda, shuffle_idx)\n",
        "        else:\n",
        "            mixup_lambda = np.ones(x.shape[0])\n",
        "            shuffle_idx = np.arange(x.shape[0])\n",
        "        return x, frames_num, mixup_lambda, shuffle_idx\n",
        "        \n",
        "\n",
        "    def forward(self, input, mixup_lambda=None):\n",
        "        \"\"\"\n",
        "        Input: (batch_size, data_length)\"\"\"\n",
        "        x, frames_num, mixup_lambda, shuffle_idx = self.preprocess(input)\n",
        "\n",
        "        # Output shape (batch size, channels, time, frequency)\n",
        "        x = self.cnn_feature_extractor(x)\n",
        "        \n",
        "        # Aggregate in frequency axis\n",
        "        x = torch.mean(x, dim=3)\n",
        "\n",
        "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
        "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
        "        x = x1 + x2\n",
        "\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = F.relu_(self.fc1(x))\n",
        "        x = x.transpose(1, 2)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
        "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
        "\n",
        "        # Get framewise output\n",
        "        framewise_output = interpolate(segmentwise_output,\n",
        "                                       self.interpolate_ratio)\n",
        "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
        "\n",
        "        output_dict = {\n",
        "            'framewise_output': framewise_output,\n",
        "            'clipwise_output': clipwise_output,\n",
        "            'mixup_param':(mixup_lambda,shuffle_idx)      \n",
        "        }\n",
        "\n",
        "        return output_dict"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_4A38aafJ9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SR = 32000\n",
        "\n",
        "# f = fs.open(TRAIN_RESAMPLED_AUDIO_DIRS[3] + \"normoc/XC277358.wav\")\n",
        "# y, _ = sf.read(f, dtype='float32')\n",
        "\n",
        "# Audio(y, rate=SR)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:44.961633Z",
          "iopub.status.busy": "2020-08-14T10:26:44.960605Z",
          "iopub.status.idle": "2020-08-14T10:26:46.429944Z",
          "shell.execute_reply": "2020-08-14T10:26:46.431123Z"
        },
        "papermill": {
          "duration": 1.508482,
          "end_time": "2020-08-14T10:26:46.431338",
          "exception": false,
          "start_time": "2020-08-14T10:26:44.922856",
          "status": "completed"
        },
        "tags": [],
        "id": "OFf3wSIIN33Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_config = {\n",
        "    \"sample_rate\": 32000,\n",
        "    \"window_size\": 1024,\n",
        "    \"hop_size\": 320,\n",
        "    \"mel_bins\": 64,\n",
        "    \"fmin\": 50,\n",
        "    \"fmax\": 14000,\n",
        "    \"classes_num\": 264\n",
        "}\n",
        "\n",
        "model = PANNsCNN14Att(**model_config)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIjkTqQNDREb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_file_list=[['gs://kds-415a60f0bab644c1dede2edf10f91cfeaad783c1b318ff35aa8a6057/aldfly/XC134874.wav',\n",
        "#   'aldfly'],\n",
        "#  ['gs://kds-415a60f0bab644c1dede2edf10f91cfeaad783c1b318ff35aa8a6057/aldfly/XC135454.wav',\n",
        "#   'aldfly'],\n",
        "#  ['gs://kds-415a60f0bab644c1dede2edf10f91cfeaad783c1b318ff35aa8a6057/aldfly/XC135455.wav',\n",
        "#   'aldfly'],\n",
        "#  ['gs://kds-415a60f0bab644c1dede2edf10f91cfeaad783c1b318ff35aa8a6057/aldfly/XC135456.wav',\n",
        "#   'aldfly'],\n",
        "#  ['gs://kds-415a60f0bab644c1dede2edf10f91cfeaad783c1b318ff35aa8a6057/aldfly/XC135457.wav',\n",
        "#   'aldfly'],\n",
        "#  ['gs://kds-415a60f0bab644c1dede2edf10f91cfeaad783c1b318ff35aa8a6057/aldfly/XC135459.wav',\n",
        "#   'aldfly'],\n",
        "#  ['gs://kds-415a60f0bab644c1dede2edf10f91cfeaad783c1b318ff35aa8a6057/aldfly/XC135460.wav',\n",
        "#   'aldfly'],\n",
        "#  ['gs://kds-415a60f0bab644c1dede2edf10f91cfeaad783c1b318ff35aa8a6057/aldfly/XC135883.wav',\n",
        "#   'aldfly'],\n",
        "#  ['gs://kds-415a60f0bab644c1dede2edf10f91cfeaad783c1b318ff35aa8a6057/aldfly/XC140298.wav',\n",
        "#   'aldfly'],\n",
        "#  ['gs://kds-415a60f0bab644c1dede2edf10f91cfeaad783c1b318ff35aa8a6057/aldfly/XC142065.wav',\n",
        "#   'aldfly']]\n",
        "# train_dataset_loader = data.DataLoader(PANNsDataset(train_file_list, None), \n",
        "#                              batch_size=8, \n",
        "#                              shuffle=True, \n",
        "#                              num_workers=16, \n",
        "#                              pin_memory=True, \n",
        "#                              drop_last=True)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:46.652351Z",
          "iopub.status.busy": "2020-08-14T10:26:46.651311Z",
          "iopub.status.idle": "2020-08-14T10:26:46.797849Z",
          "shell.execute_reply": "2020-08-14T10:26:46.801207Z"
        },
        "papermill": {
          "duration": 0.207007,
          "end_time": "2020-08-14T10:26:46.801379",
          "exception": false,
          "start_time": "2020-08-14T10:26:46.594372",
          "status": "completed"
        },
        "tags": [],
        "id": "dlSgTcVUN33b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_batch = next(iter(train_dataset_loader))\n",
        "# chunk = train_batch#torch.from_numpy(y[:SR * 5]).unsqueeze(0)\n",
        "# melspec, _,_ = model.preprocess(chunk['waveform'])\n",
        "# melspec.size()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgSJ8EI8MdLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# melspec_numpy = melspec.detach().numpy()[0, 0].transpose(1, 0)\n",
        "# display.specshow(melspec_numpy, sr=SR, y_axis=\"mel\");"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:47.400179Z",
          "iopub.status.busy": "2020-08-14T10:26:47.398645Z",
          "iopub.status.idle": "2020-08-14T10:26:48.027748Z",
          "shell.execute_reply": "2020-08-14T10:26:48.026756Z"
        },
        "papermill": {
          "duration": 0.75626,
          "end_time": "2020-08-14T10:26:48.027863",
          "exception": false,
          "start_time": "2020-08-14T10:26:47.271603",
          "status": "completed"
        },
        "tags": [],
        "id": "XyeMG2K0N33h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature_map = model.cnn_feature_extractor(melspec)\n",
        "# feature_map.size()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHvk0TNNHdHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# out = model.forward(train_batch['waveform'])\n",
        "# out"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.031231,
          "end_time": "2020-08-14T10:26:48.347603",
          "exception": false,
          "start_time": "2020-08-14T10:26:48.316372",
          "status": "completed"
        },
        "tags": [],
        "id": "NkC7t8ElN33k",
        "colab_type": "text"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:48.444830Z",
          "iopub.status.busy": "2020-08-14T10:26:48.429645Z",
          "iopub.status.idle": "2020-08-14T10:26:48.461345Z",
          "shell.execute_reply": "2020-08-14T10:26:48.460812Z"
        },
        "papermill": {
          "duration": 0.082421,
          "end_time": "2020-08-14T10:26:48.461444",
          "exception": false,
          "start_time": "2020-08-14T10:26:48.379023",
          "status": "completed"
        },
        "tags": [],
        "id": "RD3TGbEzN33k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BIRD_CODE = {\n",
        "    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,\n",
        "    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,\n",
        "    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,\n",
        "    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,\n",
        "    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,\n",
        "    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,\n",
        "    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,\n",
        "    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,\n",
        "    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,\n",
        "    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,\n",
        "    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'cacwre': 54,\n",
        "    'calgul': 55, 'calqua': 56, 'camwar': 57, 'cangoo': 58, 'canwar': 59,\n",
        "    'canwre': 60, 'carwre': 61, 'casfin': 62, 'caster1': 63, 'casvir': 64,\n",
        "    'cedwax': 65, 'chispa': 66, 'chiswi': 67, 'chswar': 68, 'chukar': 69,\n",
        "    'clanut': 70, 'cliswa': 71, 'comgol': 72, 'comgra': 73, 'comloo': 74,\n",
        "    'commer': 75, 'comnig': 76, 'comrav': 77, 'comred': 78, 'comter': 79,\n",
        "    'comyel': 80, 'coohaw': 81, 'coshum': 82, 'cowscj1': 83, 'daejun': 84,\n",
        "    'doccor': 85, 'dowwoo': 86, 'dusfly': 87, 'eargre': 88, 'easblu': 89,\n",
        "    'easkin': 90, 'easmea': 91, 'easpho': 92, 'eastow': 93, 'eawpew': 94,\n",
        "    'eucdov': 95, 'eursta': 96, 'evegro': 97, 'fiespa': 98, 'fiscro': 99,\n",
        "    'foxspa': 100, 'gadwal': 101, 'gcrfin': 102, 'gnttow': 103, 'gnwtea': 104,\n",
        "    'gockin': 105, 'gocspa': 106, 'goleag': 107, 'grbher3': 108, 'grcfly': 109,\n",
        "    'greegr': 110, 'greroa': 111, 'greyel': 112, 'grhowl': 113, 'grnher': 114,\n",
        "    'grtgra': 115, 'grycat': 116, 'gryfly': 117, 'haiwoo': 118, 'hamfly': 119,\n",
        "    'hergul': 120, 'herthr': 121, 'hoomer': 122, 'hoowar': 123, 'horgre': 124,\n",
        "    'horlar': 125, 'houfin': 126, 'houspa': 127, 'houwre': 128, 'indbun': 129,\n",
        "    'juntit1': 130, 'killde': 131, 'labwoo': 132, 'larspa': 133, 'lazbun': 134,\n",
        "    'leabit': 135, 'leafly': 136, 'leasan': 137, 'lecthr': 138, 'lesgol': 139,\n",
        "    'lesnig': 140, 'lesyel': 141, 'lewwoo': 142, 'linspa': 143, 'lobcur': 144,\n",
        "    'lobdow': 145, 'logshr': 146, 'lotduc': 147, 'louwat': 148, 'macwar': 149,\n",
        "    'magwar': 150, 'mallar3': 151, 'marwre': 152, 'merlin': 153, 'moublu': 154,\n",
        "    'mouchi': 155, 'moudov': 156, 'norcar': 157, 'norfli': 158, 'norhar2': 159,\n",
        "    'normoc': 160, 'norpar': 161, 'norpin': 162, 'norsho': 163, 'norwat': 164,\n",
        "    'nrwswa': 165, 'nutwoo': 166, 'olsfly': 167, 'orcwar': 168, 'osprey': 169,\n",
        "    'ovenbi1': 170, 'palwar': 171, 'pasfly': 172, 'pecsan': 173, 'perfal': 174,\n",
        "    'phaino': 175, 'pibgre': 176, 'pilwoo': 177, 'pingro': 178, 'pinjay': 179,\n",
        "    'pinsis': 180, 'pinwar': 181, 'plsvir': 182, 'prawar': 183, 'purfin': 184,\n",
        "    'pygnut': 185, 'rebmer': 186, 'rebnut': 187, 'rebsap': 188, 'rebwoo': 189,\n",
        "    'redcro': 190, 'redhea': 191, 'reevir1': 192, 'renpha': 193, 'reshaw': 194,\n",
        "    'rethaw': 195, 'rewbla': 196, 'ribgul': 197, 'rinduc': 198, 'robgro': 199,\n",
        "    'rocpig': 200, 'rocwre': 201, 'rthhum': 202, 'ruckin': 203, 'rudduc': 204,\n",
        "    'rufgro': 205, 'rufhum': 206, 'rusbla': 207, 'sagspa1': 208, 'sagthr': 209,\n",
        "    'savspa': 210, 'saypho': 211, 'scatan': 212, 'scoori': 213, 'semplo': 214,\n",
        "    'semsan': 215, 'sheowl': 216, 'shshaw': 217, 'snobun': 218, 'snogoo': 219,\n",
        "    'solsan': 220, 'sonspa': 221, 'sora': 222, 'sposan': 223, 'spotow': 224,\n",
        "    'stejay': 225, 'swahaw': 226, 'swaspa': 227, 'swathr': 228, 'treswa': 229,\n",
        "    'truswa': 230, 'tuftit': 231, 'tunswa': 232, 'veery': 233, 'vesspa': 234,\n",
        "    'vigswa': 235, 'warvir': 236, 'wesblu': 237, 'wesgre': 238, 'weskin': 239,\n",
        "    'wesmea': 240, 'wessan': 241, 'westan': 242, 'wewpew': 243, 'whbnut': 244,\n",
        "    'whcspa': 245, 'whfibi': 246, 'whtspa': 247, 'whtswi': 248, 'wilfly': 249,\n",
        "    'wilsni1': 250, 'wiltur': 251, 'winwre3': 252, 'wlswar': 253, 'wooduc': 254,\n",
        "    'wooscj2': 255, 'woothr': 256, 'y00475': 257, 'yebfly': 258, 'yebsap': 259,\n",
        "    'yehbla': 260, 'yelwar': 261, 'yerwar': 262, 'yetvir': 263\n",
        "}\n",
        "\n",
        "INV_BIRD_CODE = {v: k for k, v in BIRD_CODE.items()}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPJNIfaWxwrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Augmentation\n",
        "\n",
        "import albumentations\n",
        "\n",
        "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
        "\n",
        "class AudioTransform(BasicTransform):\n",
        "    \"\"\"Transform for Audio task\"\"\"\n",
        "\n",
        "    @property\n",
        "    def targets(self):\n",
        "        return {\"data\": self.apply}\n",
        "    \n",
        "    def update_params(self, params, **kwargs):\n",
        "        if hasattr(self, \"interpolation\"):\n",
        "            params[\"interpolation\"] = self.interpolation\n",
        "        if hasattr(self, \"fill_value\"):\n",
        "            params[\"fill_value\"] = self.fill_value\n",
        "        return params\n",
        "        \n",
        "class RandomAudio(AudioTransform):\n",
        "    \"\"\"Shifting time axis\"\"\"\n",
        "    def __init__(self,  seconds=5, always_apply=False, p=0.5):\n",
        "        super(RandomAudio, self).__init__(always_apply, p)\n",
        "\n",
        "        self.seconds = seconds\n",
        "    \n",
        "    def apply(self, data, **params):\n",
        "        sound, sr = data\n",
        "\n",
        "        shift = np.random.randint(len(sound))\n",
        "        trim_sound = np.roll(sound, shift)\n",
        "\n",
        "        min_samples = int(sr * self.seconds)\n",
        "\n",
        "        if len(trim_sound) < min_samples:\n",
        "            padding = min_samples - len(trim_sound)\n",
        "            offset = padding // 2\n",
        "            trim_sound = np.pad(trim_sound, (offset, padding - offset), \"constant\")\n",
        "        else:\n",
        "            trim_sound = trim_sound[:min_samples]\n",
        "\n",
        "        return trim_sound, sr\n",
        "    \n",
        "\n",
        "    \n",
        "class AddGaussianNoise(AudioTransform):\n",
        "    \"\"\"Shifting time axis\"\"\"\n",
        "    def __init__(self, always_apply=False, p=0.5):\n",
        "        super(AddGaussianNoise, self).__init__(always_apply, p)\n",
        "    \n",
        "    def apply(self, data, **params):\n",
        "        sound, sr = data\n",
        "        noise = 0.005*np.random.uniform()*np.amax(sound)\n",
        "        augmented_sound = np.array(sound).astype('float64') + noise * np.random.normal(size=sound.shape[0])\n",
        "        return augmented_sound, sr\n",
        "    \n",
        "waveform_transforms = albumentations.Compose([\n",
        "    #RandomAudio(always_apply=True),\n",
        "    AddGaussianNoise(p=0.5),\n",
        "    \n",
        "])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:48.540845Z",
          "iopub.status.busy": "2020-08-14T10:26:48.540238Z",
          "iopub.status.idle": "2020-08-14T10:26:48.544594Z",
          "shell.execute_reply": "2020-08-14T10:26:48.544102Z"
        },
        "papermill": {
          "duration": 0.050901,
          "end_time": "2020-08-14T10:26:48.544697",
          "exception": false,
          "start_time": "2020-08-14T10:26:48.493796",
          "status": "completed"
        },
        "tags": [],
        "id": "6oq9W4zfN33m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PERIOD = 15\n",
        "\n",
        "class PANNsDataset(data.Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            file_list: List[List[str]],\n",
        "            waveform_transforms=None):\n",
        "        self.file_list = file_list  # list of list: [file_path, ebird_code]\n",
        "        self.waveform_transforms = waveform_transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        wav_path, ebird_code = self.file_list[idx]\n",
        "\n",
        "        f = fs.open(wav_path)\n",
        "        y, sr = sf.read(f)\n",
        "\n",
        "        if self.waveform_transforms:\n",
        "            \n",
        "            y,sr = self.waveform_transforms(data=(y,sr))['data']\n",
        "        \n",
        "        len_y = len(y)\n",
        "        effective_length = sr * PERIOD\n",
        "        if len_y < effective_length:\n",
        "            new_y = np.zeros(effective_length, dtype=y.dtype)\n",
        "            start = np.random.randint(effective_length - len_y)\n",
        "            new_y[start:start + len_y] = y\n",
        "            y = new_y.astype(np.float32)\n",
        "        elif len_y > effective_length:\n",
        "            start = np.random.randint(len_y - effective_length)\n",
        "            y = y[start:start + effective_length].astype(np.float32)\n",
        "        else:\n",
        "            y = y.astype(np.float32)\n",
        "\n",
        "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
        "        labels[BIRD_CODE[ebird_code]] = 1\n",
        "\n",
        "        return {\"waveform\": y, \"targets\": labels}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:48.692139Z",
          "iopub.status.busy": "2020-08-14T10:26:48.691461Z",
          "iopub.status.idle": "2020-08-14T10:26:48.695848Z",
          "shell.execute_reply": "2020-08-14T10:26:48.695373Z"
        },
        "papermill": {
          "duration": 0.054385,
          "end_time": "2020-08-14T10:26:48.695948",
          "exception": false,
          "start_time": "2020-08-14T10:26:48.641563",
          "status": "completed"
        },
        "tags": [],
        "id": "Ce1ekjusN33o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PANNsLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bce = nn.BCELoss()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        mixup_lambda,shuffle_idx = input['mixup_param']\n",
        "        mixup_lambda =  mixup_lambda.reshape(-1,1)\n",
        "        input_ = input[\"clipwise_output\"]\n",
        "        input_ = torch.where(torch.isnan(input_),\n",
        "                             torch.zeros_like(input_),\n",
        "                             input_)\n",
        "        input_ = torch.where(torch.isinf(input_),\n",
        "                             torch.zeros_like(input_),\n",
        "                             input_)\n",
        "        target_mixup = do_mixup(target, mixup_lambda, shuffle_idx)\n",
        "\n",
        "        input_ = torch.clamp(input_, 0.0, 1.0)\n",
        "        return self.bce(input_, target_mixup)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:48.854976Z",
          "iopub.status.busy": "2020-08-14T10:26:48.849889Z",
          "iopub.status.idle": "2020-08-14T10:26:48.858082Z",
          "shell.execute_reply": "2020-08-14T10:26:48.857544Z"
        },
        "papermill": {
          "duration": 0.065321,
          "end_time": "2020-08-14T10:26:48.858189",
          "exception": false,
          "start_time": "2020-08-14T10:26:48.792868",
          "status": "completed"
        },
        "tags": [],
        "id": "HlJ0O9XwN33s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class F1Callback(Callback):\n",
        "    valid_f1_score = []\n",
        "    to_save = False\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_key: str = \"targets\",\n",
        "                 output_key: str = \"logits\",\n",
        "                 model_output_key: str = \"clipwise_output\",\n",
        "                 mixup_key: str = \"mixup_param\", \n",
        "                 prefix: str = \"f1\"):\n",
        "        super().__init__(CallbackOrder.Metric)\n",
        "\n",
        "        self.input_key = input_key\n",
        "        self.output_key = output_key\n",
        "        self.mixup_key = mixup_key\n",
        "        self.model_output_key = model_output_key\n",
        "        self.prefix = prefix\n",
        "        \n",
        "\n",
        "    def on_loader_start(self, state: State):\n",
        "        self.prediction: List[np.ndarray] = []\n",
        "        self.target: List[np.ndarray] = []\n",
        "\n",
        "    def on_batch_end(self, state: State):\n",
        "        targ = state.input[self.input_key]\n",
        "        out = state.output[self.output_key]\n",
        "        \n",
        "        \n",
        "        mixup_lambda,shuffle_idx = out[self.mixup_key]\n",
        "        mixup_lambda = mixup_lambda.reshape(-1,1)\n",
        "        targ = do_mixup(targ, mixup_lambda,shuffle_idx).detach().cpu().numpy()\n",
        "\n",
        "\n",
        "        clipwise_output = out[self.model_output_key].detach().cpu().numpy()\n",
        "\n",
        "        self.prediction.append(clipwise_output)\n",
        "        self.target.append(targ)\n",
        "\n",
        "        y_pred = clipwise_output.argmax(axis=1)\n",
        "        y_true = targ.argmax(axis=1)\n",
        "\n",
        "        score = f1_score(y_true, y_pred, average=\"micro\")\n",
        "        state.batch_metrics[self.prefix] = score\n",
        "\n",
        "    def on_loader_end(self, state: State):\n",
        "        y_pred = np.concatenate(self.prediction, axis=0).argmax(axis=1)\n",
        "        y_true = np.concatenate(self.target, axis=0).argmax(axis=1)\n",
        "        \n",
        "        score = f1_score(y_true, y_pred, average=\"micro\")\n",
        "        state.loader_metrics[self.prefix] = score\n",
        "        if state.is_valid_loader:\n",
        "            state.epoch_metrics[state.valid_loader + \"_epoch_\" + self.prefix] = score\n",
        "            self.valid_f1_score.append(score)\n",
        "            if score == max(self.valid_f1_score):\n",
        "                self.to_save = True\n",
        "            else:\n",
        "                self.to_save = False\n",
        "        else:\n",
        "            state.epoch_metrics[\"train_epoch_\" + self.prefix] = score\n",
        "\n",
        "    # Checkpoint by F1 score\n",
        "    def on_epoch_end(self, runner: IRunner):\n",
        "        logdir = weight_path\n",
        "        if self.to_save:\n",
        "            utils.save_checkpoint(\n",
        "                checkpoint=utils.pack_checkpoint(model=runner.model),\n",
        "                logdir=Path(logdir),\n",
        "                suffix='best',\n",
        "                saver_fn=save,\n",
        "            )\n",
        "        with open(logdir + f'/{version_name}_f1.txt', 'w') as f:\n",
        "            f.write('Best Micro F1: %.6f  Best epoch: %d\\n' % (max(self.valid_f1_score), np.argmax(self.valid_f1_score)+1))\n",
        "            for i, f1 in enumerate(self.valid_f1_score):\n",
        "                f.write('Epoch %d Micro F1: %.6f\\n' % (i+1, f1))\n",
        "\n",
        "class mAPCallback(Callback):\n",
        "    valid_mAP_score = []\n",
        "    to_save = False\n",
        "    def __init__(self,\n",
        "                 input_key: str = \"targets\",\n",
        "                 output_key: str = \"logits\",\n",
        "                 model_output_key: str = \"clipwise_output\",\n",
        "                 prefix: str = \"mAP\"):\n",
        "        super().__init__(CallbackOrder.Metric)\n",
        "        self.input_key = input_key\n",
        "        self.output_key = output_key\n",
        "        self.model_output_key = model_output_key\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def on_loader_start(self, state: State):\n",
        "        self.prediction: List[np.ndarray] = []\n",
        "        self.target: List[np.ndarray] = []\n",
        "\n",
        "    def on_batch_end(self, state: State):\n",
        "        targ = state.input[self.input_key].detach().cpu().numpy()\n",
        "        out = state.output[self.output_key]\n",
        "\n",
        "        clipwise_output = out[self.model_output_key].detach().cpu().numpy()\n",
        "\n",
        "        self.prediction.append(clipwise_output)\n",
        "        self.target.append(targ)\n",
        "\n",
        "        score = average_precision_score(targ, clipwise_output, average=None)\n",
        "        score = np.nan_to_num(score).mean()\n",
        "        state.batch_metrics[self.prefix] = score\n",
        "\n",
        "    def on_loader_end(self, state: State):\n",
        "        y_pred = np.concatenate(self.prediction, axis=0)\n",
        "        y_true = np.concatenate(self.target, axis=0)\n",
        "        score = average_precision_score(y_true, y_pred, average=None)\n",
        "        score = np.nan_to_num(score).mean()\n",
        "        state.loader_metrics[self.prefix] = score\n",
        "        \n",
        "        if state.is_valid_loader:\n",
        "            state.epoch_metrics[state.valid_loader + \"_epoch_\" +\n",
        "                                self.prefix] = score\n",
        "            self.valid_mAP_score.append(score)\n",
        "            if score == max(self.valid_mAP_score):\n",
        "                self.to_save = True\n",
        "            else:\n",
        "                self.to_save = False\n",
        "\n",
        "        else:\n",
        "            state.epoch_metrics[\"train_epoch_\" + self.prefix] = score\n",
        "\n",
        "    # Checkpoint by mAP score\n",
        "    def on_epoch_end(self, runner: IRunner):\n",
        "        logdir = weight_path\n",
        "        if self.to_save:\n",
        "            utils.save_checkpoint(\n",
        "                checkpoint=utils.pack_checkpoint(model=runner.model),\n",
        "                logdir=Path(logdir),\n",
        "                suffix='best',\n",
        "                saver_fn=save,\n",
        "            )\n",
        "        with open(logdir + f'/{version_name}_mAP.txt', 'w') as f:\n",
        "            f.write('Best mAP: %.6f  Best epoch: %d\\n' % (max(self.valid_mAP_score), np.argmax(self.valid_mAP_score)+1))\n",
        "            for i, f1 in enumerate(self.valid_mAP_score):\n",
        "                f.write('Epoch %d mAP: %.6f\\n' % (i+1, f1))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:49.001106Z",
          "iopub.status.busy": "2020-08-14T10:26:49.000144Z",
          "iopub.status.idle": "2020-08-14T10:26:49.708541Z",
          "shell.execute_reply": "2020-08-14T10:26:49.707629Z"
        },
        "papermill": {
          "duration": 0.749533,
          "end_time": "2020-08-14T10:26:49.708664",
          "exception": false,
          "start_time": "2020-08-14T10:26:48.959131",
          "status": "completed"
        },
        "tags": [],
        "id": "thzn75frN33v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "5ca737fe-c379-4a06-ef0a-1e779a0b9f4a"
      },
      "source": [
        "tmp_list = []\n",
        "for audio_d in TRAIN_RESAMPLED_AUDIO_DIRS:\n",
        "    if not fs.exists(audio_d):\n",
        "        continue\n",
        "    for ebird_d in fs.ls(audio_d):\n",
        "        if fs.isfile(ebird_d):\n",
        "            continue\n",
        "        for wav_f in fs.ls(ebird_d):\n",
        "            tmp_list.append([ebird_d.split('/')[-1], wav_f.split('/')[-1], 'gs://' + wav_f])\n",
        "            \n",
        "train_wav_path_exist = pd.DataFrame(\n",
        "    tmp_list, columns=[\"ebird_code\", \"resampled_filename\", \"file_path\"])\n",
        "\n",
        "del tmp_list\n",
        "\n",
        "train_all = pd.merge(\n",
        "    train, train_wav_path_exist, on=[\"ebird_code\", \"resampled_filename\"], how=\"inner\")\n",
        "\n",
        "print(train.shape)\n",
        "print(train_wav_path_exist.shape)\n",
        "print(train_all.shape)\n",
        "\n",
        "#train_all = train_all.sample(frac=0.1) # used for debugging"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21375, 38)\n",
            "(21375, 3)\n",
            "(21375, 39)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:49.806182Z",
          "iopub.status.busy": "2020-08-14T10:26:49.804681Z",
          "iopub.status.idle": "2020-08-14T10:26:49.875178Z",
          "shell.execute_reply": "2020-08-14T10:26:49.875766Z"
        },
        "papermill": {
          "duration": 0.133113,
          "end_time": "2020-08-14T10:26:49.875942",
          "exception": false,
          "start_time": "2020-08-14T10:26:49.742829",
          "status": "completed"
        },
        "tags": [],
        "id": "Y9LSMvLvN33x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f9d0843e-0f88-4b62-9cee-05bd9f8ea435"
      },
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "train_all[\"fold\"] = -1\n",
        "for fold_id, (train_index, val_index) in enumerate(skf.split(train_all, train_all[\"ebird_code\"])):\n",
        "    train_all.iloc[val_index, -1] = fold_id\n",
        "    \n",
        "# # check the propotion\n",
        "fold_proportion = pd.pivot_table(train_all, index=\"ebird_code\", columns=\"fold\", values=\"xc_id\", aggfunc=len)\n",
        "print(fold_proportion.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(264, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:49.960106Z",
          "iopub.status.busy": "2020-08-14T10:26:49.959257Z",
          "iopub.status.idle": "2020-08-14T10:26:50.006856Z",
          "shell.execute_reply": "2020-08-14T10:26:50.007827Z"
        },
        "papermill": {
          "duration": 0.094264,
          "end_time": "2020-08-14T10:26:50.007988",
          "exception": false,
          "start_time": "2020-08-14T10:26:49.913724",
          "status": "completed"
        },
        "tags": [],
        "id": "_t_lKtkzN33y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1d022bad-e5b0-45b6-8717-dbc7e738b372"
      },
      "source": [
        "use_fold = 0\n",
        "train_file_list = train_all.query(\"fold != @use_fold\")[[\"file_path\", \"ebird_code\"]].values.tolist()\n",
        "val_file_list = train_all.query(\"fold == @use_fold\")[[\"file_path\", \"ebird_code\"]].values.tolist()\n",
        "\n",
        "print(\"[fold {}] train: {}, val: {}\".format(use_fold, len(train_file_list), len(val_file_list)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[fold 0] train: 17100, val: 4275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADsc-ZZfvLPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8c39c556-c148-4f61-f814-0635ea398255"
      },
      "source": [
        "device"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:50.093491Z",
          "iopub.status.busy": "2020-08-14T10:26:50.092046Z",
          "iopub.status.idle": "2020-08-14T10:26:59.767467Z",
          "shell.execute_reply": "2020-08-14T10:26:59.766328Z"
        },
        "papermill": {
          "duration": 9.724143,
          "end_time": "2020-08-14T10:26:59.767606",
          "exception": false,
          "start_time": "2020-08-14T10:26:50.043463",
          "status": "completed"
        },
        "tags": [],
        "id": "tOxKBtPgN331",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# loaders\n",
        "loaders = {\n",
        "    \"train\": data.DataLoader(PANNsDataset(train_file_list, waveform_transforms), \n",
        "                             batch_size=48, \n",
        "                             shuffle=True, \n",
        "                             num_workers=16, \n",
        "                             pin_memory=True, \n",
        "                             drop_last=True),\n",
        "    \"valid\": data.DataLoader(PANNsDataset(val_file_list, None), \n",
        "                             batch_size=48, \n",
        "                             shuffle=False,\n",
        "                             num_workers=16,\n",
        "                             pin_memory=True,\n",
        "                             drop_last=False)\n",
        "}\n",
        "\n",
        "# model\n",
        "model_config[\"classes_num\"] = 527\n",
        "model = PANNsCNN14Att(**model_config)\n",
        "\n",
        "weights = torch.load('./Cnn14_DecisionLevelAtt_mAP0.425.pth')\n",
        "\n",
        "# Fixed in V3\n",
        "model.load_state_dict(weights[\"model\"])\n",
        "model.att_block = AttBlock(2048, 264, activation='sigmoid')\n",
        "model.att_block.init_weights()\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Scheduler\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "# Loss\n",
        "criterion = PANNsLoss().to(device)\n",
        "\n",
        "# callbacks\n",
        "callbacks = [\n",
        "    F1Callback(input_key=\"targets\", output_key=\"logits\", prefix=\"f1\"),\n",
        "    #mAPCallback(input_key=\"targets\", output_key=\"logits\", prefix=\"mAP\"),\n",
        "]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2020-08-14T10:26:59.844806Z",
          "iopub.status.busy": "2020-08-14T10:26:59.843872Z",
          "iopub.status.idle": "2020-08-14T11:06:08.770335Z",
          "shell.execute_reply": "2020-08-14T11:06:08.767243Z"
        },
        "papermill": {
          "duration": 2348.968697,
          "end_time": "2020-08-14T11:06:08.770508",
          "exception": false,
          "start_time": "2020-08-14T10:26:59.801811",
          "status": "completed"
        },
        "tags": [],
        "id": "jf5MCxpXN332",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c0a961e4-6e28-4eeb-eb8c-6110f0e1ac13"
      },
      "source": [
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "runner = SupervisedRunner(\n",
        "    device=device,\n",
        "    input_key=\"waveform\",\n",
        "    input_target_key=\"targets\")\n",
        "\n",
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    loaders=loaders,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=30,\n",
        "    verbose=True,\n",
        "    #logdir=\"/content/gdrive/My Drive/bird/fold0\",  # [Bug] if this is set, full checkpoints will always be saved no matter Checkpoint callback is added or not\n",
        "    callbacks=callbacks)\n",
        "\n",
        "# 0.5242  0.537"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/30 * Epoch (train):  51% 183/356 [03:54<02:42,  1.06it/s, f1=0.000e+00, loss=0.025]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fY4GF8HuEwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}